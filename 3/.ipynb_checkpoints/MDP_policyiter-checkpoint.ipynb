{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a00e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81659e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem():\n",
    "    def __init__(self):\n",
    "        #State Space\n",
    "        self.states = {0:'high',1:'low',2:'out_of_charge'}\n",
    "        #State Value function\n",
    "        self.state_vals = np.zeros(len(self.states))\n",
    "        #Action Space\n",
    "        self.actions = {0:'recharge',1:'walk',2:'stay'}\n",
    "        #Probability matrices\n",
    "        self.p = {self.actions[0]:np.array([[1,0,0],[0.8,0.2,0],[0.6,0.4,0]]), \\\n",
    "                  self.actions[1]:np.array([[0.6,0.4,0],[0,0.4,0.6],[0,0,1]]), \\\n",
    "                  self.actions[2]:np.array([[0.8,0.2,0],[0.2,0.4,0.4],[0,0.2,0.8]])}\n",
    "        #Inital Random Policy\n",
    "        self.policy = {'high':'recharge','low':'recharge','out_of_charge':'recharge'}\n",
    "        #Discount factor\n",
    "        self.gamma = 0.99\n",
    "    #Reward for different states\n",
    "    def get_reward(self,state,action):\n",
    "        if action == self.actions[0]:\n",
    "            return 0\n",
    "        if action == self.actions[1]:\n",
    "            if state == self.states[2]:\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        if action == self.actions[2]:\n",
    "            return 0\n",
    "    #State-Action value function\n",
    "    def action_val_func(self,state):\n",
    "        value = np.zeros(len(self.states))\n",
    "        for i in range(len(self.actions)):\n",
    "            for j in range(len(self.states)):\n",
    "                r = self.get_reward(self.states[j],self.actions[i])\n",
    "                value[i] += self.p[self.actions[i]][state,j]*(r + \\\n",
    "                                                              self.gamma*self.state_vals[j])\n",
    "        return self.actions[np.argmax(value)]\n",
    "    #Policy Evaluation\n",
    "    def policy_eval(self):\n",
    "        eps = 0.01\n",
    "        while True:\n",
    "            delta = 0\n",
    "            values = self.state_vals\n",
    "            for i in range(len(self.states)):\n",
    "                for j in range(len(self.states)):\n",
    "                    old_val = self.state_vals[i]\n",
    "                    r = self.get_reward(self.states[i],self.policy[self.states[i]])\n",
    "                    self.state_vals[i] += self.p[self.policy[self.states[i]]][i,j]*(r + \\\n",
    "                                                                               self.gamma*values[j])\n",
    "                delta = max(delta, abs(self.state_vals[i] - old_val))\n",
    "            if delta < eps:\n",
    "                break\n",
    "    #Policy Improvement            \n",
    "    def policy_improv(self):\n",
    "        policy_stable = True\n",
    "        for i in range(len(self.policy)):\n",
    "            old_action = self.policy[self.states[i]]\n",
    "            \n",
    "            new_action = self.action_val_func(i)\n",
    "            \n",
    "            self.policy[self.states[i]] = new_action\n",
    "            \n",
    "            if old_action != new_action:\n",
    "                policy_stable = False\n",
    "        return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215eaa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy: {'high': 'walk', 'low': 'recharge', 'out_of_charge': 'recharge'}\n",
      "Optimal state value function: [1.         0.948816   0.96973114]\n",
      "Iterations: 3\n"
     ]
    }
   ],
   "source": [
    "problem = Problem()\n",
    "iters = 1\n",
    "#Policy Iteration\n",
    "while(True):\n",
    "    iters += 1\n",
    "    problem.policy_eval()\n",
    "    done = problem.policy_improv()\n",
    "    #Exit if Policy is stable\n",
    "    if done == True:\n",
    "        break\n",
    "print(\"Optimal Policy:\",problem.policy)\n",
    "print(\"Optimal state value function:\",problem.state_vals)\n",
    "print(\"Iterations:\",iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5fe18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1191a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
